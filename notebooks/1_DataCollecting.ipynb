{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyrosm\n",
      "  Using cached pyrosm-0.6.2-cp311-cp311-macosx_11_0_arm64.whl\n",
      "Collecting python-rapidjson (from pyrosm)\n",
      "  Obtaining dependency information for python-rapidjson from https://files.pythonhosted.org/packages/7a/68/d65ae2af413c5159fedcb7ce6fa491437439767e7ff0cbd4efea78395e8b/python_rapidjson-1.20-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached python_rapidjson-1.20-cp311-cp311-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pyrosm) (75.1.0)\n",
      "Requirement already satisfied: geopandas>=0.12.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pyrosm) (0.14.4)\n",
      "Requirement already satisfied: shapely>=2.0.1 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pyrosm) (2.0.6)\n",
      "Collecting cykhash (from pyrosm)\n",
      "  Using cached cykhash-2.0.1-cp311-cp311-macosx_11_0_arm64.whl\n",
      "Collecting pyrobuf (from pyrosm)\n",
      "  Using cached pyrobuf-0.9.3-cp311-cp311-macosx_11_0_arm64.whl\n",
      "Requirement already satisfied: fiona>=1.8.21 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (1.24.3)\n",
      "Requirement already satisfied: packaging in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (3.7.0)\n",
      "Requirement already satisfied: jinja2>=2.8 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pyrobuf->pyrosm) (3.1.4)\n",
      "Collecting cython>=0.23 (from pyrobuf->pyrosm)\n",
      "  Obtaining dependency information for cython>=0.23 from https://files.pythonhosted.org/packages/43/39/bdbec9142bc46605b54d674bf158a78b191c2b75be527c6dcf3e6dfe90b8/Cython-3.0.11-py2.py3-none-any.whl.metadata\n",
      "  Using cached Cython-3.0.11-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (24.2.0)\n",
      "Requirement already satisfied: certifi in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (2024.8.30)\n",
      "Requirement already satisfied: click~=8.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from jinja2>=2.8->pyrobuf->pyrosm) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas>=0.12.0->pyrosm) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas>=0.12.0->pyrosm) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas>=0.12.0->pyrosm) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas>=0.12.0->pyrosm) (1.16.0)\n",
      "Using cached python_rapidjson-1.20-cp311-cp311-macosx_11_0_arm64.whl (210 kB)\n",
      "Using cached Cython-3.0.11-py2.py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: cykhash, python-rapidjson, cython, pyrobuf, pyrosm\n",
      "Successfully installed cykhash-2.0.1 cython-3.0.11 pyrobuf-0.9.3 pyrosm-0.6.2 python-rapidjson-1.20\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyrosm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tinas/anaconda3/envs/group25env/lib/python3.11/site-packages/pyproj/__init__.py:96: UserWarning: Valid PROJ data directory not found. Either set the path using the environmental variable PROJ_DATA (PROJ 9.1+) | PROJ_LIB (PROJ<9.1) or with `pyproj.datadir.set_data_dir`.\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyrosm import get_data\n",
    "from pyrosm.data import sources\n",
    "from pyrosm import get_data\n",
    "from pyrosm import OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the Victoria DataPack ZIP file...\n",
      "Download successful!\n",
      "File saved to '../data/landing/Victoria_DataPack.zip' successfully!\n",
      "Extracting the ZIP file...\n",
      "DataPack extracted to '../data/landing/Victoria_DataPack' successfully!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.abs.gov.au/census/find-census-data/datapacks/download/2021_GCP_SA2_for_VIC_short-header.zip\"\n",
    "print(\"Downloading the Victoria DataPack ZIP file...\")\n",
    "basepath = \"../data/landing\"\n",
    "\n",
    "os.makedirs(basepath, exist_ok=True)\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful!\")\n",
    "\n",
    "\n",
    "    file_path = os.path.join(basepath, \"Victoria_DataPack.zip\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File saved to '{file_path}' successfully!\")\n",
    "\n",
    "    output_dir = os.path.join(basepath, \"Victoria_DataPack\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Extracting the ZIP file...\")\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    \n",
    "    print(f\"DataPack extracted to '{output_dir}' successfully!\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transport Data \n",
    "\n",
    "- Retrieve all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting main zip file: ../data/landing/gtfs/gtfs.zip\n",
      "Extracted ../data/landing/gtfs/gtfs.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/11/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/11/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/7/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/7/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/6/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/6/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/1/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/1/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/10/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/10/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/8/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/8/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/4/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/4/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/3/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/3/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/2/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/2/google_transit.zip successfully!\n",
      "Found nested zip file: ../data/landing/gtfs/5/google_transit.zip, extracting...\n",
      "Extracted nested zip file: ../data/landing/gtfs/5/google_transit.zip successfully!\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../data/landing/gtfs\"\n",
    "\n",
    "# URL for the GTFS zip file\n",
    "url = \"https://data.ptv.vic.gov.au/downloads/gtfs.zip\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "    print(f\"Created directory: {base_dir}\")\n",
    "\n",
    "# Path where the main zip file will be saved\n",
    "main_zip_path = os.path.join(base_dir, \"gtfs.zip\")\n",
    "\n",
    "# Download the GTFS zip file\n",
    "if not os.path.exists(main_zip_path):\n",
    "    print(f\"Downloading {url}...\")\n",
    "    response = requests.get(url)\n",
    "    with open(main_zip_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Downloaded and saved {main_zip_path} successfully!\")\n",
    "\n",
    "# Check if the main zip file exists and proceed with extraction\n",
    "if os.path.exists(main_zip_path):\n",
    "    print(f\"Extracting main zip file: {main_zip_path}\")\n",
    "    \n",
    "    # Extract the main zip file\n",
    "    with zipfile.ZipFile(main_zip_path, 'r') as main_zip:\n",
    "        main_zip.extractall(base_dir)\n",
    "    \n",
    "    print(f\"Extracted {main_zip_path} successfully!\")\n",
    "    \n",
    "    # Iterate through extracted files and handle any zip files inside\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        \n",
    "        # Check if it is a directory (the unzipped folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Check if the file is a zip file\n",
    "                if zipfile.is_zipfile(file_path):\n",
    "                    print(f\"Found nested zip file: {file_path}, extracting...\")\n",
    "                    \n",
    "                    # Extract the nested zip file\n",
    "                    with zipfile.ZipFile(file_path, 'r') as nested_zip:\n",
    "                        nested_zip.extractall(folder_path)\n",
    "                    \n",
    "                    print(f\"Extracted nested zip file: {file_path} successfully!\")\n",
    "else:\n",
    "    print(f\"No main zip file found at {main_zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful!\n",
      "File saved to '../data/landing/gtfs/gtfs.zip' successfully!\n",
      "Extracting the ZIP file...\n",
      "DataPack extracted to '../data/landing/gtfs/gtfs' successfully!\n"
     ]
    }
   ],
   "source": [
    "ptv = \"https://data.ptv.vic.gov.au/downloads/gtfs.zip\"  \n",
    "\n",
    "response = requests.get(ptv)  \n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful!\")\n",
    "\n",
    "    file_path = os.path.join(base_dir, \"gtfs.zip\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File saved to '{file_path}' successfully!\")\n",
    "\n",
    "    output_dir = os.path.join(base_dir, \"gtfs\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Extracting the ZIP file...\")\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    \n",
    "    print(f\"DataPack extracted to '{output_dir}' successfully!\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['africa', 'antarctica', 'asia', 'australia_oceania', 'central_america', 'europe', 'north_america', 'south_america', 'cities', 'subregions'])\n",
      "['Aachen', 'Aarhus', 'Adelaide', 'Albuquerque', 'Alexandria', 'Amsterdam', 'Antwerpen', 'Arnhem', 'Auckland', 'Augsburg', 'Austin', 'Baghdad', 'Baku', 'Balaton', 'Bamberg', 'Bangkok', 'Barcelona', 'Basel', 'Beijing', 'Beirut', 'Berkeley', 'Berlin', 'Bern', 'Bielefeld', 'Birmingham', 'Bochum', 'Bogota', 'Bombay', 'Bonn', 'Bordeaux', 'Boulder', 'BrandenburgHavel', 'Braunschweig', 'Bremen', 'Bremerhaven', 'Brisbane', 'Bristol', 'Brno', 'Bruegge', 'Bruessel', 'Budapest', 'BuenosAires', 'Cairo', 'Calgary', 'Cambridge', 'CambridgeMa', 'Canberra', 'CapeTown', 'Chemnitz', 'Chicago', 'ClermontFerrand', 'Colmar', 'Copenhagen', 'Cork', 'Corsica', 'Corvallis', 'Cottbus', 'Cracow', 'CraterLake', 'Curitiba', 'Cusco', 'Dallas', 'Darmstadt', 'Davis', 'DenHaag', 'Denver', 'Dessau', 'Dortmund', 'Dresden', 'Dublin', 'Duesseldorf', 'Duisburg', 'Edinburgh', 'Eindhoven', 'Emden', 'Erfurt', 'Erlangen', 'Eugene', 'Flensburg', 'FortCollins', 'Frankfurt', 'FrankfurtOder', 'Freiburg', 'Gdansk', 'Genf', 'Gent', 'Gera', 'Glasgow', 'Gliwice', 'Goerlitz', 'Goeteborg', 'Goettingen', 'Graz', 'Groningen', 'Halifax', 'Halle', 'Hamburg', 'Hamm', 'Hannover', 'Heilbronn', 'Helsinki', 'Hertogenbosch', 'Huntsville', 'Innsbruck', 'Istanbul', 'Jena', 'Jerusalem', 'Johannesburg', 'Kaiserslautern', 'Karlsruhe', 'Kassel', 'Katowice', 'Kaunas', 'Kiel', 'Kiew', 'Koblenz', 'Koeln', 'Konstanz', 'LaPaz', 'LaPlata', 'LakeGarda', 'Lausanne', 'Leeds', 'Leipzig', 'Lima', 'Linz', 'Lisbon', 'Liverpool', 'Ljubljana', 'Lodz', 'London', 'Luebeck', 'Luxemburg', 'Lyon', 'Maastricht', 'Madison', 'Madrid', 'Magdeburg', 'Mainz', 'Malmoe', 'Manchester', 'Mannheim', 'Marseille', 'Melbourne', 'Memphis', 'MexicoCity', 'Miami', 'Moenchengladbach', 'Montevideo', 'Montpellier', 'Montreal', 'Moscow', 'Muenchen', 'Muenster', 'NewDelhi', 'NewOrleans', 'NewYorkCity', 'Nuernberg', 'Oldenburg', 'Oranienburg', 'Orlando', 'Oslo', 'Osnabrueck', 'Ostrava', 'Ottawa', 'Paderborn', 'Palma', 'PaloAlto', 'Paris', 'Perth', 'Philadelphia', 'PhnomPenh', 'Portland', 'PortlandME', 'Porto', 'PortoAlegre', 'Potsdam', 'Poznan', 'Prag', 'Providence', 'Regensburg', 'Riga', 'RiodeJaneiro', 'Rostock', 'Rotterdam', 'Ruegen', 'Saarbruecken', 'Sacramento', 'Saigon', 'Salzburg', 'SanFrancisco', 'SanJose', 'SanktPetersburg', 'SantaBarbara', 'SantaCruz', 'Santiago', 'Sarajewo', 'Schwerin', 'Seattle', 'Seoul', 'Sheffield', 'Singapore', 'Sofia', 'Stockholm', 'Stockton', 'Strassburg', 'Stuttgart', 'Sucre', 'Sydney', 'Szczecin', 'Tallinn', 'Tehran', 'Tilburg', 'Tokyo', 'Toronto', 'Toulouse', 'Trondheim', 'Tucson', 'Turin', 'UlanBator', 'Ulm', 'Usedom', 'Utrecht', 'Vancouver', 'Victoria', 'WarenMueritz', 'Warsaw', 'WashingtonDC', 'Waterloo', 'Wien', 'Wroclaw', 'Wuerzburg', 'Wuppertal', 'Zagreb', 'Zuerich']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sources.available.keys())\n",
    "print(sources.cities.available)\n",
    "\n",
    "basepath = \"../data/landing\"\n",
    "fp = get_data(\"Melbourne\", directory=basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(\"../data/landing/OSM/\"), exist_ok=True)\n",
    "fp = get_data(\"Melbourne\", directory=\"../data/landing/OSM/\")\n",
    "osm = OSM(fp)\n",
    "custom_filter = {'amenity': True, \"shop\": True}\n",
    "pois = osm.get_pois(custom_filter=custom_filter)\n",
    "\n",
    "custom_filter = {\n",
    "    'amenity': ['hospital', 'fire_station', 'police', 'pharmacy'],\n",
    "    'shop': ['mall', 'supermarket'],\n",
    "    'nature': ['beach', 'scrub']\n",
    "}\n",
    "\n",
    "pois = osm.get_pois(custom_filter=custom_filter)\n",
    "\n",
    "pois[\"poi_type\"] = pois[\"amenity\"]\n",
    "pois[\"poi_type\"] = pois[\"poi_type\"].fillna(pois[\"shop\"])\n",
    "\n",
    "# Plot the POIs categorized by 'poi_type'\n",
    "ax = pois.plot(column='poi_type', markersize=3, figsize=(12, 12), legend=True, \n",
    "               legend_kwds=dict(loc='upper left', ncol=5, bbox_to_anchor=(1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois.to_csv(\"../data/landing/amenities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mall = pois.loc[pois['poi_type'] == \"mall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mall.to_csv(os.path.join(basepath, \"malls_melb.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful!\n",
      "File saved to '../data/landing/SA2_2021_AUST_SHP_GDA2020.zip' successfully!\n",
      "Extracting the ZIP file...\n",
      "DataPack extracted to '../data/landing/SA2_2021_AUST_SHP_GDA2020' successfully!\n"
     ]
    }
   ],
   "source": [
    "\"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "\n",
    "SA2_shapefile = \"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "\n",
    "basepath = \"../data/landing\"\n",
    "response = requests.get(SA2_shapefile)  \n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful!\")\n",
    "\n",
    "    \n",
    "    file_path = os.path.join(basepath, \"SA2_2021_AUST_SHP_GDA2020.zip\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File saved to '{file_path}' successfully!\")\n",
    "\n",
    "    output_dir = os.path.join(basepath, \"SA2_2021_AUST_SHP_GDA2020\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Extracting the ZIP file...\")\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    \n",
    "    print(f\"DataPack extracted to '{output_dir}' successfully!\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "schoolurl = \"https://www.education.vic.gov.au/Documents/about/research/datavic/dv346-schoollocations2023.csv\"\n",
    "\n",
    "response = requests.get(schoolurl)\n",
    "\n",
    "with open(\"../data/landing/dv346-schoollocations2023.csv\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to ../data/historical/Data_Tables_LGA_Recorded_Offences_June_2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "url = \"https://files.crimestatistics.vic.gov.au/2024-09/Data_Tables_LGA_Recorded_Offences_Year_Ending_June_2024.xlsx\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "file_path = \"../data/historical/Data_Tables_LGA_Recorded_Offences_June_2024.xlsx\"\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"File saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as '../data/landing/australian_postcodes.csv'.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.matthewproctor.com/Content/postcodes/australian_postcodes.csv\"\n",
    "\n",
    "file_name = \"../data/landing/australian_postcodes.csv\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  #\n",
    "\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(f\"File downloaded successfully and saved as '{file_name}'.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Failed to download the file. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes = pd.read_csv(\"../data/landing/australian_postcodes.csv\")\n",
    "postcodes = postcodes.loc[postcodes[\"state\"] == \"VIC\"][[\"postcode\",\"locality\",\"state\"]]\n",
    "postcodes[\"locality\"] = postcodes[\"locality\"].apply(lambda x: x.lower())\n",
    "postcodes[\"locality\"] = postcodes[\"locality\"].apply(lambda x: x.replace(\" \", \"-\"))\n",
    "postcodes [\"state\"] = postcodes[\"state\"].apply(lambda x: x.lower())\n",
    "postcodes[\"url\"] = postcodes[\"locality\"] + \"-\" + postcodes[\"state\"] + \"-\" + postcodes[\"postcode\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['melbourne-vic-3000', 'melbourne-vic-3001',\n",
       "       'east-melbourne-vic-3002', ..., 'dandenong-vic-8785',\n",
       "       'dandenong-south-vic-8785', 'north-pole-vic-9999'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcodes[\"url\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albert-park',\n",
       " 'armadale',\n",
       " 'carlton-north',\n",
       " 'carlton',\n",
       " 'melbourne',\n",
       " 'collingwood',\n",
       " 'docklands',\n",
       " 'east-melbourne',\n",
       " 'east-st-kilda',\n",
       " 'elwood',\n",
       " 'fitzroy',\n",
       " 'fitzroy-north',\n",
       " 'flemington',\n",
       " 'north-melbourne',\n",
       " 'port-melbourne',\n",
       " 'prahran',\n",
       " 'richmond',\n",
       " 'south-melbourne',\n",
       " 'south-yarra',\n",
       " 'southbank',\n",
       " 'st-kilda',\n",
       " 'toorak',\n",
       " 'balwyn',\n",
       " 'blackburn',\n",
       " 'box-hill',\n",
       " 'bulleen',\n",
       " 'burwood',\n",
       " 'camberwell',\n",
       " 'canterbury',\n",
       " 'chadstone',\n",
       " 'clayton',\n",
       " 'doncaster-east',\n",
       " 'east-hawthorn',\n",
       " 'glen-waverley',\n",
       " 'hawthorn',\n",
       " 'kew',\n",
       " 'mount-waverley',\n",
       " 'nunawading',\n",
       " 'vermont',\n",
       " 'aspendale',\n",
       " 'bentleigh',\n",
       " 'brighton',\n",
       " 'brighton-east',\n",
       " 'carnegie',\n",
       " 'caulfield',\n",
       " 'cheltenham',\n",
       " 'elsternwick',\n",
       " 'hampton',\n",
       " 'malvern',\n",
       " 'malvern-east',\n",
       " 'mentone',\n",
       " 'murrumbeena',\n",
       " 'altona',\n",
       " 'footscray',\n",
       " 'keilor-east',\n",
       " 'melton',\n",
       " 'newport',\n",
       " 'st-albans',\n",
       " 'sunshine',\n",
       " 'sydenham',\n",
       " 'werribee',\n",
       " 'west-footscray',\n",
       " 'williamstown',\n",
       " 'yarraville',\n",
       " 'broadmeadows',\n",
       " 'brunswick',\n",
       " 'coburg',\n",
       " 'craigieburn',\n",
       " 'east-brunswick',\n",
       " 'essendon',\n",
       " 'gladstone-park',\n",
       " 'keilor',\n",
       " 'moonee-ponds',\n",
       " 'oak-park',\n",
       " 'pascoe-vale',\n",
       " 'sunbury',\n",
       " 'west-brunswick',\n",
       " 'bundoora',\n",
       " 'eltham',\n",
       " 'fairfield',\n",
       " 'heidelberg',\n",
       " 'ivanhoe',\n",
       " 'mill-park',\n",
       " 'northcote',\n",
       " 'preston',\n",
       " 'reservoir',\n",
       " 'thomastown',\n",
       " 'thornbury',\n",
       " 'whittlesea',\n",
       " 'bayswater',\n",
       " 'boronia',\n",
       " 'croydon',\n",
       " 'ferntree-gully',\n",
       " 'ringwood',\n",
       " 'rowville',\n",
       " 'wantirna',\n",
       " 'yarra-ranges',\n",
       " 'berwick',\n",
       " 'cranbourne',\n",
       " 'dandenong',\n",
       " 'dandenong-north',\n",
       " 'narre-warren',\n",
       " 'noble-park',\n",
       " 'pakenham',\n",
       " 'springvale',\n",
       " 'dromana',\n",
       " 'frankston',\n",
       " 'hastings',\n",
       " 'mt-eliza',\n",
       " 'seaford',\n",
       " 'belmont-grovedale',\n",
       " 'corio',\n",
       " 'geelong',\n",
       " 'herne-hill',\n",
       " 'lara',\n",
       " 'newtown',\n",
       " 'north-geelong',\n",
       " 'ballarat',\n",
       " 'mount-clear',\n",
       " 'sebastopol',\n",
       " 'wendouree',\n",
       " 'bendigo',\n",
       " 'flora-hill',\n",
       " 'golden-square',\n",
       " 'north-bendigo',\n",
       " 'bairnsdale',\n",
       " 'benalla',\n",
       " 'castlemaine',\n",
       " 'echuca',\n",
       " 'hamilton',\n",
       " 'horsham',\n",
       " 'mildura',\n",
       " 'moe',\n",
       " 'morwell',\n",
       " 'ocean-grove',\n",
       " 'portland',\n",
       " 'sale',\n",
       " 'seymour',\n",
       " 'shepparton',\n",
       " 'swan-hill',\n",
       " 'torquay',\n",
       " 'traralgon',\n",
       " 'wanagaratta',\n",
       " 'warragul',\n",
       " 'warrnambool',\n",
       " 'wodonga']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suburbs_interested= \"\"\"Albert-Park\n",
    "Armadale\n",
    "Carlton-North\n",
    "Carlton\n",
    "Melbourne\n",
    "Collingwood\n",
    "Docklands\n",
    "East-Melbourne\n",
    "East-St-Kilda\n",
    "Elwood\n",
    "Fitzroy\n",
    "Fitzroy-North\n",
    "Flemington\n",
    "North-Melbourne\n",
    "Port-Melbourne\n",
    "Prahran\n",
    "Richmond\n",
    "South-Melbourne\n",
    "South-Yarra\n",
    "Southbank\n",
    "St-Kilda\n",
    "Toorak\n",
    "Balwyn\n",
    "Blackburn\n",
    "Box-Hill\n",
    "Bulleen\n",
    "Burwood\n",
    "Camberwell\n",
    "Canterbury\n",
    "Chadstone\n",
    "Clayton\n",
    "Doncaster-East\n",
    "East-Hawthorn\n",
    "Glen-Waverley\n",
    "Hawthorn\n",
    "Kew\n",
    "Mount-Waverley\n",
    "Nunawading\n",
    "Vermont\n",
    "Aspendale\n",
    "Bentleigh\n",
    "Brighton\n",
    "Brighton-East\n",
    "Carnegie\n",
    "Caulfield\n",
    "Cheltenham\n",
    "Elsternwick\n",
    "Hampton\n",
    "Malvern\n",
    "Malvern-East\n",
    "Mentone\n",
    "Murrumbeena\n",
    "Altona\n",
    "Footscray\n",
    "Keilor-East\n",
    "Melton\n",
    "Newport\n",
    "St-Albans\n",
    "Sunshine\n",
    "Sydenham\n",
    "Werribee\n",
    "West-Footscray\n",
    "Williamstown\n",
    "Yarraville\n",
    "Broadmeadows\n",
    "Brunswick\n",
    "Coburg\n",
    "Craigieburn\n",
    "East-Brunswick\n",
    "Essendon\n",
    "Gladstone-Park\n",
    "Keilor\n",
    "Moonee-Ponds\n",
    "Oak-Park\n",
    "Pascoe-Vale\n",
    "Sunbury\n",
    "West-Brunswick\n",
    "Bundoora\n",
    "Eltham\n",
    "Fairfield\n",
    "Heidelberg\n",
    "Ivanhoe\n",
    "Mill-Park\n",
    "Northcote\n",
    "Preston\n",
    "Reservoir\n",
    "Thomastown\n",
    "Thornbury\n",
    "Whittlesea\n",
    "Bayswater\n",
    "Boronia\n",
    "Croydon\n",
    "Ferntree-Gully\n",
    "Ringwood\n",
    "Rowville\n",
    "Wantirna\n",
    "Yarra-Ranges\n",
    "Berwick\n",
    "Cranbourne\n",
    "Dandenong\n",
    "Dandenong-North\n",
    "Narre-Warren\n",
    "Noble-Park\n",
    "Pakenham\n",
    "Springvale\n",
    "Dromana\n",
    "Frankston\n",
    "Hastings\n",
    "Mt-Eliza\n",
    "Seaford\n",
    "Belmont-Grovedale\n",
    "Corio\n",
    "Geelong\n",
    "Herne-Hill\n",
    "Lara\n",
    "Newtown\n",
    "North-Geelong\n",
    "Ballarat\n",
    "Mount-Clear\n",
    "Sebastopol\n",
    "Wendouree\n",
    "Bendigo\n",
    "Flora-Hill\n",
    "Golden-Square\n",
    "North-Bendigo\n",
    "Bairnsdale\n",
    "Benalla\n",
    "Castlemaine\n",
    "Echuca\n",
    "Hamilton\n",
    "Horsham\n",
    "Mildura\n",
    "Moe\n",
    "Morwell\n",
    "Ocean-Grove\n",
    "Portland\n",
    "Sale\n",
    "Seymour\n",
    "Shepparton\n",
    "Swan-Hill\n",
    "Torquay\n",
    "Traralgon\n",
    "Wanagaratta\n",
    "Warragul\n",
    "Warrnambool\n",
    "Wodonga\"\"\"\n",
    "suburbs_interested = suburbs_interested.split(\"\\n\")\n",
    "suburbs_interested = [x.lower() for x in suburbs_interested]\n",
    "suburbs_interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes = postcodes.loc[postcodes[\"locality\"].isin(suburbs_interested)]\n",
    "postcodes.to_csv(\"../data/landing/url-site.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(postcodes[\"url\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
